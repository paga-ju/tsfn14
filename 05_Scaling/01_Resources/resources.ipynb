{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "- A **resource** commonly refers to:\n",
    " \n",
    "  - **Memory** is the **working memory capability** of a physical or virtual machine (or a Pod's container) and is expressed in **bytes**.\n",
    "  - **CPU** is the **compute capability** of a physical or virtual machine (or a Pod's container) and is expressed in **CPU cores**.\n",
    "    - **GPU** is a similar resource but on a **graphics card** with its own **on-board memory**.\n",
    "  - **Storage** is the **storage capacity** of a physical or virtual machine (or a Pod's container) and is expressed in **bytes**.\n",
    "    - Other metrics use for storage, besides capacity, is e.g. latency, throughput, IOPS, utilization, and queue length.\n",
    "  - **Network** is the **network capacity** of a physical or virtual machine (or a Pod's container) and is expressed in **bits/second**.\n",
    "    - Other metrics use for network, is e.g. latency (s), throughput (bps), speed (bps), bandwidth (bps), jitter, packet loss, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources in Kubernetes\n",
    "\n",
    "- A **Node** can be a **Physical Machine**, a **Virtual Machine**, or a **Container**.\n",
    "  - In a Kubernetes scenario (at least for Cloud Providers), a **Node is a Virtual Machine** unning on a **Physical Machine**.\n",
    "- A **Physical Machine** has a number of **CPU cores** (an integer value) and **Memory** (bytes).\n",
    "  - A **Physical Machine** can have multiple **CPUs (sockets)**, where each CPU socker can have multiple **CPU cores** per socket.\n",
    "- Each **Container** running in a **Pod** on a **Node** utilizes a certain amout of a **Physical Machine's** resources (CPU cores and Memory).\n",
    "  - If we sum this resource utilization for **Containers** running on a **Node** (**Virtual Machine**) we get the **Node's** utilization.\n",
    "- For **Nodes** (**Virtual Machines**) and Pod **Containers** we are interested in two aspects of these `resources`:\n",
    "  - `requests` which is the minimum amount of resources (`cpu` cores and `memory`) that a **Node/Container** requests from the **Physical Machine**.\n",
    "  - `limits` which is the maximum amount of resources (`cpu` cores and `memory`) that a **Node/Container** is permitted to use.\n",
    "\n",
    "- Assume we have one **Node** running some **Pods**, each with one **Container**.\n",
    "  - Here we see the:\n",
    "    - `resource limits` (maximum allowable `cpu` cores and `memory`) for the **Node**.\n",
    "    - `resource requests` (minimum `cpu` cores and `memory`) for the **Containers**.\n",
    "\n",
    "  <img src=\"../notebook_images/v_node_scaling_before.png\" alt=\"Before Scaling\" width=\"280\" height=\"260\" style=\"margin-bottom:2em\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Resource Requests and Limits for a Pod's Containers\n",
    "\n",
    "<img src=\"../notebook_images/resources.png\" alt=\"HPA YAML\" width=\"700\" height=\"300\" style=\"margin-bottom:2em; float: right\">\n",
    "\n",
    "- A **Pod** can define <span style=\"color:#DDDD00;font-weight:bold\">resouces</span> for each container, where:\n",
    "  - <span style=\"color:#DDDD00;font-weight:bold\">requests</span> defines the minimum **cpu** and **memory**.\n",
    "  - <span style=\"color:#DDDD00;font-weight:bold\">limits</span> defines the maximum **cpu** and **memory**.\n",
    "- If a **Container**:\n",
    "  - Exceeds its **memory** <span style=\"color:#DDDD00;font-weight:bold\">limits</span>, it is terminated.\n",
    "    - i.e. the **kubelet** restarts the **Container**.\n",
    "  - Approaches its **CPU** <span style=\"color:#DDDD00;font-weight:bold\">limits</span>, it is throttled.\n",
    "    - i.e. the **Container** can't use more **cpu** than this.\n",
    "- If a **Container** doesn't specify any <span style=\"color:#DDDD00;font-weight:bold\">resouces</span>:\n",
    "  - It can use an unlimited amount of **cpu** and **memory**.\n",
    "  - It might hog all **cpu** and **memory** on the **Node**.\n",
    "  - It might crash (bring down) the **Node**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure a Kubenetes cluster is running\n",
    "\n",
    "- Use any Kubernetes cluster.\n",
    "  - In this example, a Minikube cluster with 3 nodes is used: `minikube start --nodes 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable the `metrics-server` Minikube addon (if using Minikube)\n",
    "\n",
    "- Kubenetes uses the `metrics-server` to monitor `resources`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡  metrics-server is an addon maintained by Kubernetes. For any concerns contact minikube on GitHub.\n",
      "You can view the list of minikube maintainers at: https://github.com/kubernetes/minikube/blob/master/OWNERS\n",
      "    â–ª Using image registry.k8s.io/metrics-server/metrics-server:v0.6.4\n",
      "ðŸŒŸ  The 'metrics-server' addon is enabled\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n",
      "|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n",
      "| ambassador                  | minikube | disabled     | 3rd party (Ambassador)         |\n",
      "| auto-pause                  | minikube | disabled     | minikube                       |\n",
      "| cloud-spanner               | minikube | disabled     | Google                         |\n",
      "| csi-hostpath-driver         | minikube | disabled     | Kubernetes                     |\n",
      "| dashboard                   | minikube | disabled     | Kubernetes                     |\n",
      "| default-storageclass        | minikube | disabled     | Kubernetes                     |\n",
      "| efk                         | minikube | disabled     | 3rd party (Elastic)            |\n",
      "| freshpod                    | minikube | disabled     | Google                         |\n",
      "| gcp-auth                    | minikube | disabled     | Google                         |\n",
      "| gvisor                      | minikube | disabled     | minikube                       |\n",
      "| headlamp                    | minikube | disabled     | 3rd party (kinvolk.io)         |\n",
      "| helm-tiller                 | minikube | disabled     | 3rd party (Helm)               |\n",
      "| inaccel                     | minikube | disabled     | 3rd party (InAccel             |\n",
      "|                             |          |              | [info@inaccel.com])            |\n",
      "| ingress                     | minikube | disabled     | Kubernetes                     |\n",
      "| ingress-dns                 | minikube | disabled     | minikube                       |\n",
      "| inspektor-gadget            | minikube | disabled     | 3rd party                      |\n",
      "|                             |          |              | (inspektor-gadget.io)          |\n",
      "| istio                       | minikube | disabled     | 3rd party (Istio)              |\n",
      "| istio-provisioner           | minikube | disabled     | 3rd party (Istio)              |\n",
      "| kong                        | minikube | disabled     | 3rd party (Kong HQ)            |\n",
      "| kubeflow                    | minikube | disabled     | 3rd party                      |\n",
      "| kubevirt                    | minikube | disabled     | 3rd party (KubeVirt)           |\n",
      "| logviewer                   | minikube | disabled     | 3rd party (unknown)            |\n",
      "| metallb                     | minikube | disabled     | 3rd party (MetalLB)            |\n",
      "| metrics-server              | minikube | enabled âœ…   | Kubernetes                     |\n",
      "| nvidia-device-plugin        | minikube | disabled     | 3rd party (NVIDIA)             |\n",
      "| nvidia-driver-installer     | minikube | disabled     | 3rd party (Nvidia)             |\n",
      "| nvidia-gpu-device-plugin    | minikube | disabled     | 3rd party (Nvidia)             |\n",
      "| olm                         | minikube | disabled     | 3rd party (Operator Framework) |\n",
      "| pod-security-policy         | minikube | disabled     | 3rd party (unknown)            |\n",
      "| portainer                   | minikube | disabled     | 3rd party (Portainer.io)       |\n",
      "| registry                    | minikube | disabled     | minikube                       |\n",
      "| registry-aliases            | minikube | disabled     | 3rd party (unknown)            |\n",
      "| registry-creds              | minikube | disabled     | 3rd party (UPMC Enterprises)   |\n",
      "| storage-provisioner         | minikube | disabled     | minikube                       |\n",
      "| storage-provisioner-gluster | minikube | disabled     | 3rd party (Gluster)            |\n",
      "| storage-provisioner-rancher | minikube | disabled     | 3rd party (Rancher)            |\n",
      "| volumesnapshots             | minikube | disabled     | Kubernetes                     |\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n"
     ]
    }
   ],
   "source": [
    "!minikube addons enable metrics-server\n",
    "!minikube addons list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Metrics Server (if not using Minikube)\n",
    "\n",
    "- To check if the Metrics Server is installed in your cluster, look for a pod called `metrics-server` in the `kube-system` namespace\n",
    "  -  `kubectl get po -n kube-system`\n",
    "- To install the Metrics Server\n",
    "  - Download the YAML file `components.yaml` from `https://github.com/kubernetes-sigs/metrics-server/releases`\n",
    "  - Edit the `components.yaml` file and add the parameter `- --kubelet-insecure-tls` to the `Deployment` section.\n",
    "    - This enables the Metrics Server to run if TLS is not configured.\n",
    "  - Install the Metrics Server with `kubectl apply -f components.yaml`.\n",
    "\n",
    "```bash\n",
    "# components.yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  labels:\n",
    "    k8s-app: metrics-server\n",
    "  name: metrics-server\n",
    "  namespace: kube-system\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      k8s-app: metrics-server\n",
    "  strategy:\n",
    "    rollingUpdate:\n",
    "      maxUnavailable: 0\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        k8s-app: metrics-server\n",
    "    spec:\n",
    "      containers:\n",
    "      - args:\n",
    "        - --cert-dir=/tmp\n",
    "        - --secure-port=443\n",
    "        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\n",
    "        - --kubelet-use-node-status-port\n",
    "        - --kubelet-insecure-tls # <-------------------------------------------- Add this line\n",
    "        - --metric-resolution=15s\n",
    "        image: k8s.gcr.io/metrics-server/metrics-server:v0.5.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f manifests/components.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's list the current CPU and Memory utilization for every node\n",
    "\n",
    "- **Note:** It might take a minute before the `metrics-server` has collected enough metrics for the nodes.\n",
    "- CPU is measured in **cpu units**.\n",
    "  - **1** CPU unit is equivalent to either:\n",
    "    - 1 physical CPU core, if the machine is a physical host.\n",
    "    - 1 virtual core, if the machine is a virtual machine (or container) running inside a physical machine.\n",
    "  - Fractional values, e.g. **0.5**, means half as much CPU time is used compared to using **1.0** CPU.\n",
    "    - For CPU resource units, the quantity expression **0.1** is equivalent to the expression **100m**, which can be read as \"one hundred millicpu\".\n",
    "      - Some people say \"one hundred millicores\", and this is understood to mean the same thing.\n",
    "  - CPU resources are always specified as an absolute amount of resource, never as a relative amount.\n",
    "    - E.g. **500m** represents the same amount of computing power (half a CPU core).\n",
    "      - Irrespective if the pysical machine has a single-core, dual-cores, or 48-cores.\n",
    "- Memory is measured in **bytes**.\n",
    "  - Memory can be expressed as a plain integer or as a fixed-point number using one of the quantity suffixes:\n",
    "    - **E**, **P**, **T**, **G**, **M**, **k** (**E**ta bytes, **P**eta bytes, **T**era bytes, **G**iga bytes, **M**ega bytes, **K**ilo bytes), e.g. 1**K** is 1 kilobyte = 1000 bytes.\n",
    "    - You can also use the power-of-two equivalents: **Ei**, **Pi**, **Ti**, **Gi**, **Mi**, **Ki**, e.g 1**Ki** is 1 kebibyte = 1024 bytes.\n",
    "    - You can also use the suffix **m** for millibytes, e.g. 1000**m** is 1 millibyte = 1 byte.\n",
    "    - E.g., the following represent roughly the same value: 128974848, 129e6, 129**M**, 123**Mi**, 128974848000**m**\n",
    "  \n",
    "  In this example, the three Minikube nodes are currently using the following CPU and Memory resources:\n",
    "  - The `minikube` node is using:\n",
    "    - `157m` (0.176) CPU cores (`0%`) of total available CPU resources.\n",
    "    - `968Mi` (762 memibytes) of Memory (`6%`) of total available memory resources.\n",
    "  - The `minikube-m02` node is using:\n",
    "    - `43m` (0.046) CPU cores (`0%`) of total available CPU resources.\n",
    "    - `269Mi` (268 memibytes) of Memory (`1%`) of total available memory resources.\n",
    "  - The `minikube-m03` node is using:\n",
    "    - `35m` (0.039) CPU cores (`0%`) of total available CPU resources.\n",
    "    - `225Mi` (226 memibytes) of Memory (`1%`) of total available memory resources.\n",
    "\n",
    "  ```bash\n",
    "  NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \n",
    "  minikube       157m         0%     968Mi           6%\n",
    "  minikube-m02   43m          0%     269Mi           1%\n",
    "  minikube-m03   35m          0%     225Mi           1%\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \n",
      "minikube       157m         0%     968Mi           6%        \n",
      "minikube-m02   43m          0%     269Mi           1%        \n",
      "minikube-m03   35m          0%     225Mi           1%        \n"
     ]
    }
   ],
   "source": [
    "!kubectl top nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pods\n",
    "\n",
    "- The following Pod's use stress images (used to stress the cpu/memory in a container).\n",
    "  - All Pod definitions have  `replicas` set to `1`.\n",
    "\n",
    "- The Pod definitions are in the YAML files as below:\n",
    "  - CPU tests:\n",
    "    - `manifests/within-node-cpu-limit.yaml`\n",
    "      - the container's cpu (and memory) doesn't exceed the node's cpu and memory\n",
    "      - the container tries to use 2 cpu cores, but is limited (throttled) to 0.030 cpu cores\n",
    "      - the Pod will run, although the microservice might run slower than expected\n",
    "\n",
    "      ```bash\n",
    "      resources:\n",
    "        requests:            # minimum cpu is 0.015 cores, minimum memory is 100 mebibytes\n",
    "          cpu: 15m\n",
    "          memory: 100Mi\n",
    "        limits:              # maximum cpu is 0.030 cores, minimum memory is 200 mebibytes\n",
    "          cpu: 30m\n",
    "          memory: 200Mi\n",
    "      args: [\"-cpus\", \"2\"]   # the pod's container actaully uses 2 cores (the stress test)\n",
    "      ```\n",
    "\n",
    "    - `manifests/over-node-cpu-limit.yaml`\n",
    "      - the container's requested cpu exceeds the node's cpu limit\n",
    "      - the Pod will not run if no node can accomodate the contaienr's resource demands\n",
    "        - the Pods `STATE` will be `pending` (util an appropriate node becomes available)\n",
    "\n",
    "      ```bash\n",
    "      resources:\n",
    "        requests:            # minimum cpu is 100 cores, minimum memory is 100 mebibytes\n",
    "          cpu: 100000m\n",
    "          memory: 100Mi\n",
    "        limits:              # maximum cpu is 100 cores, minimum memory is 200 mebibytes\n",
    "          cpu: 100000m\n",
    "          memory: 200Mi\n",
    "      args: [\"-cpus\", \"2\"]   # the pod's container actually uses 2 cores (the stress test)\n",
    "      ```\n",
    "\n",
    "  - Memory tests: \n",
    "    - `manifests/within-container-memory-limit.yaml`\n",
    "      - the container's memory utilization (150M) is within its memory limit (200Mi)\n",
    "      - the Pod will run as normal without any hicks\n",
    "\n",
    "      ```bash\n",
    "      resources:\n",
    "        requests:            # minimum cpu is 0.015 cores, minimum memory is 100 mebibytes\n",
    "          cpu: 15m\n",
    "          memory: 100Mi\n",
    "        limits:              # maximum cpu is 0.030 cores, minimum memory is 200 mebibytes\n",
    "          cpu: 30m\n",
    "          memory: 200Mi\n",
    "      command: [stress]      # the pod's container actually uses 150 megabytes (the stress test)\n",
    "      args: [\"--vm\", \"1\", \"--vm-bytes\", \"150M\", \"--vm-hang\", \"1\"]\n",
    "      ```\n",
    "    \n",
    "    - `manifests/over-container-memory-limit.yaml`\n",
    "      - the container's memeory utilization (250M) exceeds its memory limit (100Mi)\n",
    "      - the kubelet running on the node will restart the Pod\n",
    "        - first, the Pod's `STATE` will be `OOMKilled` (Out Of Memory, so the Pod was killed)\n",
    "        - then the Pod will be restarted by the kubelet\n",
    "        - finally, the Pod's `STATE` will be `CrashLoopBackOff` (keeps crashing, so not restarted for a while)\n",
    "\n",
    "      ```bash\n",
    "      resources:\n",
    "        requests:            # minimum cpu is 0.015 cores, minimum memory is 50 mebibytes\n",
    "          cpu: 15m\n",
    "          memory: 50Mi\n",
    "        limits:              # maximum cpu is 0.030 cores, minimum memory is 100 mebibytes\n",
    "          cpu: 30m\n",
    "          memory: 100Mi\n",
    "      command: [stress]      # the pod's container actually uses 250 megabytes (the stress test)\n",
    "      args: [\"--vm\", \"1\", \"--vm-bytes\", \"250M\", \"--vm-hang\", \"1\"]\n",
    "      ```\n",
    "  \n",
    "    - `manifests/over-node-memory-limit.yaml`\n",
    "      - the container's requested memory exceeds the node's available memory\n",
    "      - the Pod will not run if no node can accomodate the contaienr's resource demands\n",
    "        - the Pods `STATE` will be `pending` (util an appropriate node becomes available)\n",
    "\n",
    "      ```bash\n",
    "      resources:\n",
    "        requests:            # minimum cpu is 0.015 cores, minimum memory is 1000 gibibytes (1 tebibyte)\n",
    "          cpu: 15m\n",
    "          memory: 1000Gi\n",
    "        limits:              # maximum cpu is 0.030 cores, minimum memory is 1000 gibibytes (1 tebibyte)\n",
    "          cpu: 30m\n",
    "          memory: 1000Gi\n",
    "      command: [stress]      # the pod's container actually uses 150 megabytes (the stress test)\n",
    "      args: [\"--vm\", \"1\", \"--vm-bytes\", \"150M\", \"--vm-hang\", \"1\"]\n",
    "      ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/within-container-memory-limit created\n",
      "pod/over-container-memory-limit created\n",
      "pod/over-node-memory-limit created\n",
      "pod/within-node-cpu-limit created\n",
      "pod/over-node-cpu-limit created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f manifests/within-container-memory-limit.yaml\n",
    "!kubectl apply -f manifests/over-container-memory-limit.yaml\n",
    "!kubectl apply -f manifests/over-node-memory-limit.yaml\n",
    "\n",
    "!kubectl apply -f manifests/within-node-cpu-limit.yaml\n",
    "!kubectl apply -f manifests/over-node-cpu-limit.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Pods\n",
    "\n",
    "- We see that the `STATUS` is:\n",
    "  - `OOMKilled` for the `over-container-memory-limit` pod.\n",
    "    - this pod was killed since it's container's memory utilization excceded it memory limit.\n",
    "    - the pod will be restarted, but eventually end up with a `STATUS` of `CrashLoopBackOff`.\n",
    "  - `Pending` for the `over-node-cpu-limit` and `over-node-memory-limit` pods.\n",
    "    - the `kube-scheduler` can't find an appropriate node that can accommodate the container's resource demands. \n",
    "  - `Running` for the `within-container-memory-limit` and `within-node-cpu-limit` pods.\n",
    "    - the first Pod's container's memory utilization is within its memory limit.\n",
    "    - the second Pod's cpu utilization is throttled (capped) to its cpu limit.\n",
    "\n",
    "**Note:**\n",
    "- A container that exceeds it's memory limit (`OOMKilled`) is restarted by the `kubelet`.\n",
    "- A container that tries to exceed it's cpu limit is throttled (its cpu utilization is capped) by the `kubelet`.\n",
    "- A container that demands more cpu or memory available on any node, will be in a `Pedning` state.\n",
    "\n",
    "You can run the command `kubectl get pods -o wide --watch` in a separate terminal to see that pod states chaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                            READY   STATUS      RESTARTS      AGE   IP           NODE           NOMINATED NODE   READINESS GATES\n",
      "over-container-memory-limit     0/1     OOMKilled   3 (35s ago)   61s   10.244.2.2   minikube-m03   <none>           <none>\n",
      "over-node-cpu-limit             0/1     Pending     0             60s   <none>       <none>         <none>           <none>\n",
      "over-node-memory-limit          0/1     Pending     0             60s   <none>       <none>         <none>           <none>\n",
      "within-container-memory-limit   1/1     Running     0             61s   10.244.1.3   minikube-m02   <none>           <none>\n",
      "within-node-cpu-limit           1/1     Running     0             60s   10.244.2.3   minikube-m03   <none>           <none>\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the `over-node-memory-limit` Pod\n",
    "\n",
    "- We see the `over-node-memory-limit` Pod has a `FailedScheduling` event (bottom of the listing).\n",
    "  - There is insufficient memory on any node to run the pod (who's container is demanding too much memory).\n",
    "\n",
    "  ```bash\n",
    "  Events:\n",
    "    Type     Reason            Age   From               Message\n",
    "    ----     ------            ----  ----               -------\n",
    "    Warning  FailedScheduling  13s   default-scheduler  0/3 nodes are available: 3 Insufficient memory.\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:             over-node-memory-limit\n",
      "Namespace:        default\n",
      "Priority:         0\n",
      "Service Account:  default\n",
      "Node:             <none>\n",
      "Labels:           <none>\n",
      "Annotations:      <none>\n",
      "Status:           Pending\n",
      "IP:               \n",
      "IPs:              <none>\n",
      "Containers:\n",
      "  over-node-memory-limit:\n",
      "    Image:      polinux/stress\n",
      "    Port:       <none>\n",
      "    Host Port:  <none>\n",
      "    Command:\n",
      "      stress\n",
      "    Args:\n",
      "      --vm\n",
      "      1\n",
      "      --vm-bytes\n",
      "      150M\n",
      "      --vm-hang\n",
      "      1\n",
      "    Limits:\n",
      "      cpu:     30m\n",
      "      memory:  1000Gi\n",
      "    Requests:\n",
      "      cpu:        15m\n",
      "      memory:     1000Gi\n",
      "    Environment:  <none>\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vv4cc (ro)\n",
      "Conditions:\n",
      "  Type           Status\n",
      "  PodScheduled   False \n",
      "Volumes:\n",
      "  kube-api-access-vv4cc:\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
      "    TokenExpirationSeconds:  3607\n",
      "    ConfigMapName:           kube-root-ca.crt\n",
      "    ConfigMapOptional:       <nil>\n",
      "    DownwardAPI:             true\n",
      "QoS Class:                   Burstable\n",
      "Node-Selectors:              <none>\n",
      "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
      "Events:\n",
      "  Type     Reason            Age   From               Message\n",
      "  ----     ------            ----  ----               -------\n",
      "  Warning  FailedScheduling  87s   default-scheduler  0/3 nodes are available: 3 Insufficient memory. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pod over-node-memory-limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the `over-node-cpu-limit` Pod\n",
    "\n",
    "- We see the `over-node-cpu-limit` Pod has a `FailedScheduling` event (bottom of the listing).\n",
    "  - There is insufficient cpu on any node to run the pod (who's container is demanding too much cpu).\n",
    "\n",
    "  ```bash\n",
    "  Events:\n",
    "    Type     Reason            Age   From               Message\n",
    "    ----     ------            ----  ----               -------\n",
    "    Warning  FailedScheduling  14s   default-scheduler  0/3 nodes are available: 3 Insufficient cpu.\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:             over-node-cpu-limit\n",
      "Namespace:        default\n",
      "Priority:         0\n",
      "Service Account:  default\n",
      "Node:             <none>\n",
      "Labels:           <none>\n",
      "Annotations:      <none>\n",
      "Status:           Pending\n",
      "IP:               \n",
      "IPs:              <none>\n",
      "Containers:\n",
      "  over-node-cpu-limit:\n",
      "    Image:      vish/stress\n",
      "    Port:       <none>\n",
      "    Host Port:  <none>\n",
      "    Args:\n",
      "      -cpus\n",
      "      2\n",
      "    Limits:\n",
      "      cpu:     100\n",
      "      memory:  200Mi\n",
      "    Requests:\n",
      "      cpu:        100\n",
      "      memory:     100Mi\n",
      "    Environment:  <none>\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-wjjxm (ro)\n",
      "Conditions:\n",
      "  Type           Status\n",
      "  PodScheduled   False \n",
      "Volumes:\n",
      "  kube-api-access-wjjxm:\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
      "    TokenExpirationSeconds:  3607\n",
      "    ConfigMapName:           kube-root-ca.crt\n",
      "    ConfigMapOptional:       <nil>\n",
      "    DownwardAPI:             true\n",
      "QoS Class:                   Burstable\n",
      "Node-Selectors:              <none>\n",
      "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
      "Events:\n",
      "  Type     Reason            Age   From               Message\n",
      "  ----     ------            ----  ----               -------\n",
      "  Warning  FailedScheduling  91s   default-scheduler  0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pod over-node-cpu-limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get resource utilization information for the Nodes and Pods.\n",
    "\n",
    "- For the Nodes we see that: \n",
    "  - The `minikube` node is using:\n",
    "    - `175m` `cpu` cores (`1%` of available physical `cpu` cores)\n",
    "    - `991Mi` `memory` (`6%` of available physical `memory`)\n",
    "  - The `minikube-m02` node is using:\n",
    "    - `82m` `cpu` cores (`0%` of available physical `cpu` cores)\n",
    "    - `445Mi` `memory` (`2%` of available physical `memory`)\n",
    "  - The `minikube-m03` node is using:\n",
    "    - `121m` `cpu` cores (`0%` of available physical `cpu` cores)\n",
    "    - `265Mi` `memory` (`1%` of available physical `memory`)\n",
    "  \n",
    "- For the Pods we see that:\n",
    "  - The `within-container-memory-limit` pod is using:\n",
    "    - `13m` `cpu` cores\n",
    "    - `150Mi` `memory`\n",
    "  - The `within-node-cpu-limit` pod is using:\n",
    "    - `30m` `cpu` cores\n",
    "    - `1Mi` `memory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \n",
      "minikube       175m         1%     991Mi           6%        \n",
      "minikube-m02   82m          0%     445Mi           2%        \n",
      "minikube-m03   121m         0%     265Mi           1%        \n",
      "NAME                            CPU(cores)   MEMORY(bytes)   \n",
      "within-container-memory-limit   13m          150Mi           \n",
      "within-node-cpu-limit           30m          1Mi             \n"
     ]
    }
   ],
   "source": [
    "!kubectl top nodes\n",
    "!kubectl top pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "pod \"within-container-memory-limit\" force deleted\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "pod \"over-container-memory-limit\" force deleted\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "pod \"over-node-memory-limit\" force deleted\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "pod \"within-node-cpu-limit\" force deleted\n",
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "pod \"over-node-cpu-limit\" force deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f manifests/within-container-memory-limit.yaml --grace-period=0 --force\n",
    "!kubectl delete -f manifests/over-container-memory-limit.yaml --grace-period=0 --force\n",
    "!kubectl delete -f manifests/over-node-memory-limit.yaml --grace-period=0 --force\n",
    "\n",
    "!kubectl delete -f manifests/within-node-cpu-limit.yaml --grace-period=0 --force\n",
    "!kubectl delete -f manifests/over-node-cpu-limit.yaml --grace-period=0 --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable the `metrics-server` Minikube addon (if using Minikube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ‘  \"The 'metrics-server' addon is disabled\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n",
      "|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n",
      "| ambassador                  | minikube | disabled     | 3rd party (Ambassador)         |\n",
      "| auto-pause                  | minikube | disabled     | minikube                       |\n",
      "| cloud-spanner               | minikube | disabled     | Google                         |\n",
      "| csi-hostpath-driver         | minikube | disabled     | Kubernetes                     |\n",
      "| dashboard                   | minikube | disabled     | Kubernetes                     |\n",
      "| default-storageclass        | minikube | disabled     | Kubernetes                     |\n",
      "| efk                         | minikube | disabled     | 3rd party (Elastic)            |\n",
      "| freshpod                    | minikube | disabled     | Google                         |\n",
      "| gcp-auth                    | minikube | disabled     | Google                         |\n",
      "| gvisor                      | minikube | disabled     | minikube                       |\n",
      "| headlamp                    | minikube | disabled     | 3rd party (kinvolk.io)         |\n",
      "| helm-tiller                 | minikube | disabled     | 3rd party (Helm)               |\n",
      "| inaccel                     | minikube | disabled     | 3rd party (InAccel             |\n",
      "|                             |          |              | [info@inaccel.com])            |\n",
      "| ingress                     | minikube | disabled     | Kubernetes                     |\n",
      "| ingress-dns                 | minikube | disabled     | minikube                       |\n",
      "| inspektor-gadget            | minikube | disabled     | 3rd party                      |\n",
      "|                             |          |              | (inspektor-gadget.io)          |\n",
      "| istio                       | minikube | disabled     | 3rd party (Istio)              |\n",
      "| istio-provisioner           | minikube | disabled     | 3rd party (Istio)              |\n",
      "| kong                        | minikube | disabled     | 3rd party (Kong HQ)            |\n",
      "| kubeflow                    | minikube | disabled     | 3rd party                      |\n",
      "| kubevirt                    | minikube | disabled     | 3rd party (KubeVirt)           |\n",
      "| logviewer                   | minikube | disabled     | 3rd party (unknown)            |\n",
      "| metallb                     | minikube | disabled     | 3rd party (MetalLB)            |\n",
      "| metrics-server              | minikube | disabled     | Kubernetes                     |\n",
      "| nvidia-device-plugin        | minikube | disabled     | 3rd party (NVIDIA)             |\n",
      "| nvidia-driver-installer     | minikube | disabled     | 3rd party (Nvidia)             |\n",
      "| nvidia-gpu-device-plugin    | minikube | disabled     | 3rd party (Nvidia)             |\n",
      "| olm                         | minikube | disabled     | 3rd party (Operator Framework) |\n",
      "| pod-security-policy         | minikube | disabled     | 3rd party (unknown)            |\n",
      "| portainer                   | minikube | disabled     | 3rd party (Portainer.io)       |\n",
      "| registry                    | minikube | disabled     | minikube                       |\n",
      "| registry-aliases            | minikube | disabled     | 3rd party (unknown)            |\n",
      "| registry-creds              | minikube | disabled     | 3rd party (UPMC Enterprises)   |\n",
      "| storage-provisioner         | minikube | disabled     | minikube                       |\n",
      "| storage-provisioner-gluster | minikube | disabled     | 3rd party (Gluster)            |\n",
      "| storage-provisioner-rancher | minikube | disabled     | 3rd party (Rancher)            |\n",
      "| volumesnapshots             | minikube | disabled     | Kubernetes                     |\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n"
     ]
    }
   ],
   "source": [
    "!minikube addons disable metrics-server\n",
    "!minikube addons list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uninstall the Metrics Server (if not using Minikube)\n",
    "\n",
    "- To uninstall the Metrics Server run the command: `kubectl delete -f components.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f manifests/components.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Cluster\n",
    "\n",
    "- Delete your specific Kubernetes cluster.\n",
    "  - In this example, a Minikube cluster is used, so the command is:\n",
    "\n",
    "  ```bash\n",
    "  minikube stop\n",
    "  minikube delete\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
