{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Scaling\n",
    "\n",
    "- Scaling can be done in two different ways\n",
    "  - **Vertical Scaling**.\n",
    "  - **Horizontal Scaling**.\n",
    "\n",
    "- **Vertical Scaling** implies adding more CPU, Memory and/or Storage to a physical/virtual machine or a Pod (the Pod must be restarted).\n",
    "  - **Scaling up**: adding more CPU, Memory and/or Storage.\n",
    "  - **Scaling down**: removing CPU, Memory and/or Storage.\n",
    "\n",
    "- **Horizontal Scaling** implies adding more physical/virtual machines or Pods.\n",
    "  - **Scaling out**: adding more physical/virtual machines or Pods.\n",
    "  - **Scaling in**: removing physical/virtual machines or Pods.\n",
    "\n",
    "Virtual Machines and Pods can be scaled **manually** or **automatically**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Nodes Vertically\n",
    "\n",
    "- Assume we have one **Node** running some **Pods**, each with one **Container**.\n",
    "\n",
    "  <img src=\"../notebook_images/v_node_scaling_before.png\" alt=\"Before Scaling\" width=\"280\" height=\"260\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- We can **scale up a Node** by **increasing** its **CPU and/or Memory**.\n",
    "\n",
    "  <img src=\"../notebook_images/v_node_scaling_up.png\" alt=\"Scaling Out\" width=\"700\" height=\"300\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- We can **scale down a Node** by **decreasing** its **CPU and/or Memory**.\n",
    "\n",
    "  <img src=\"../notebook_images/v_node_scaling_down.png\" alt=\"Scaling In\" width=\"700\" height=\"300\" style=\"margin-bottom:2em\">\n",
    "\n",
    "\n",
    "- The **Cluster Autoscaler** can **automatically scale down/up Nodes**. \n",
    "  - The **Cluster Autoscaler** uses the K8s **Metrics Server** to gather **Pod utilization statistics**.\n",
    "  - We won’t use the **Cluster Autoscaler** in this course.\n",
    "  - Instructions for installing and using the **Cluster Autoscaler** can be found here:\n",
    "    - https://github.com/kubernetes/autoscaler\n",
    "    - https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Nodes Horizontally\n",
    "\n",
    "- Assume we have two **Nodes**, each running a number of **Pods**.\n",
    "\n",
    "  <img src=\"../notebook_images/h_node_scaling_before.png\" alt=\"Before Scaling\" width=\"450\" height=\"250\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- We can **scale out Nodes** by **adding more Nodes** to the cluster.\n",
    "\n",
    "  <img src=\"../notebook_images/h_node_scaling_out.png\" alt=\"Scaling Out\" width=\"700\" height=\"250\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- We can **scale in Nodes** by **removing Nodes** from the cluster.\n",
    "\n",
    "  <img src=\"../notebook_images/h_node_scaling_in.png\" alt=\"Scaling In\" width=\"220\" height=\"250\" style=\"margin-bottom:2em\">\n",
    "\n",
    "\n",
    "- The **Cluster Autoscaler** can **automatically scale in/out Nodes**. \n",
    "  - The **Cluster Autoscaler** uses the K8s **Metrics Server** to gather **Pod utilization statistics**.\n",
    "  - We won’t use the **Cluster Autoscaler** in this course.\n",
    "  - Instructions for installing and using the **Cluster Autoscaler** can be found here:\n",
    "    - https://github.com/kubernetes/autoscaler\n",
    "    - https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Pods Vertically\n",
    "\n",
    "- Assume we have some **Pods**, each with one **Container**, running on one **Node**.\n",
    "  - The **node** has 100 millicores (`cpu: 100m`) and 128 mebibytes (`memory: 128Mi`).\n",
    "  - The Pod's **container** has 10 millicores (`cpu: 10m`) and 10 mebibytes (`memory: 10Mi`).\n",
    "  - The quotas of `cpu` and `memory` resources relate to the machine they are running on.\n",
    "\n",
    "  <img src=\"../notebook_images/v_pod_scaling_before.png\" alt=\"Before Scaling\" width=\"280\" height=\"260\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- We can **scale up** a **Container** (**Pod**) by **increasing its CPU and/or Memory**.\n",
    "  - Here we are adding more cpu and memory to the right Pod's container (`cpu: 15m` and `memory: 15Mi`).\n",
    "\n",
    "  <img src=\"../notebook_images/v_pod_scaling_up.png\" alt=\"Scaling Up\" width=\"700\" height=\"300\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- We can **scale down** a **Container** (**Pod**) by **decreasing its CPU and/or Memory**.\n",
    "  - Here we are removing some cpu and memory from the right Pod's container (`cpu: 5m` and `memory: 5Mi`).\n",
    "\n",
    "  <img src=\"../notebook_images/v_pod_scaling_down.png\" alt=\"Scaling Down\" width=\"700\" height=\"300\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- The **Vertical Pod Autoscaler (VPA)** can **automatically scale up/down Pods**.\n",
    "  - The **VPA** uses the K8s **Metrics Server** to gather **Pod utilization statistics**.\n",
    "  - The **VPA** is currently in beta, and we won’t use it in this course.\n",
    "  - Instructions for installing and using the **VPA** can be found here:\n",
    "    - https://github.com/kubernetes/autoscaler\n",
    "    - https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Pods Horizontally\n",
    "\n",
    "- Assume we have three **Nodes**, each running a number of **Pods**.\n",
    "\n",
    "  <img src=\"../notebook_images/h_pod_scaling_before.png\" alt=\"Before Scaling\" width=\"700\" height=\"250\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- We can **scale out Pods** by **adding more Pods**.\n",
    "\n",
    "  <img src=\"../notebook_images/h_pod_scaling_out.png\" alt=\"Scaling Out\" width=\"700\" height=\"250\" style=\"margin-bottom:2em\">\n",
    "\n",
    "- We can **scale in Pods** by **removing Pods**.\n",
    "\n",
    "  <img src=\"../notebook_images/h_pod_scaling_in.png\" alt=\"Scaling In\" width=\"700\" height=\"250\" style=\"margin-bottom:2em\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal Pod Autoscaler (HPA)\n",
    "\n",
    "- The **Horizontal Pod Autoscaler (HPA)** can **automatically scale out/in Pods**.\n",
    "  - The **HPA** uses the K8s **Metrics Server** to gather **Pod utilization statitics**.\n",
    "  - The **HPA** checks the **Metrics Server every 30 seconds**.\n",
    "\n",
    "- **Pods** must have <span style=\"color:#DDDD00;font-weight:bold\">requests</span> and <span style=\"color:#DDDD00;font-weight:bold\">limits</span> defined for its **resources**.\n",
    "\n",
    "- The **HPA autoscales** according to:\n",
    "  - The <span style=\"color:#6688FF;font-weight:bold\">minReplicas</span> and <span style=\"color:#6688FF;font-weight:bold\">maxReplicas</span> defined.\n",
    "  - By <span style=\"color:#7030A0;font-weight:bold\">monitoring a specific target (type of resource, e.g. CPU or memory) for a specific condition</span>.\n",
    "\n",
    "- The **HPA** is connected to a **target** via its **scaleTargetRef** map.\n",
    "  - Where the properties below must match the resource to monitor statistics for:\n",
    "    - The <span style=\"color:#00C800;font-weight:bold\">apiVersion</span>.\n",
    "    - The <span style=\"color:#00C800;font-weight:bold\">kind</span>.\n",
    "    - The <span style=\"color:#00C800;font-weight:bold\">name</span>.\n",
    "\n",
    "- The **HPA** has a Cooldown/Delay to prevent racing conditions:\n",
    "  - Once a **change is made**, the **HPA waits (delays) for a while**.\n",
    "  - By default, the **delay on scale out events is 3 minutes**.\n",
    "  - By default, the **delay on scale in events is 5 minutes**.\n",
    "\n",
    "<img src=\"../notebook_images/hpa_yaml.png\" alt=\"HPA YAML\" width=\"1000\" height=\"550\" style=\"margin-bottom:2em\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `kubectl` commands for the HPA\n",
    "\n",
    "\n",
    "| Command                                                                           | Description                         |\n",
    "| :-------------------------------------------------------------------------------- | :---------------------------------- |\n",
    "| `kubectl autoscale deployment [DeploymentName] --cpu-percent=50 --min=3 --max=10` | Create HPA (CPU 50%, min 3, max 10) |\n",
    "| `kubectl apply -f [HPAYAMLFile]`                                                  | Apply HPA (create/update HPA)       |\n",
    "| `kubectl get hpa [HPAName]`                                                       | Get HPA Status                      |\n",
    "| `kubectl delete -f [HPAYAMLFile]`                                                 | Delete HPA                          |\n",
    "| `kubectl delete hpa [HPAName]`                                                    | Delete HPA                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure a Kubenetes cluster is running\n",
    "\n",
    "- Use any Kubernetes cluster.\n",
    "  - In this example, a Minikube cluster with 3 nodes is used: `minikube start --nodes 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable the `metrics-server` Minikube addon (if using Minikube)\n",
    "\n",
    "- The Horizontal Pod Autoscaler (HPA) uses the metrics collected by the `metrics-server`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡  metrics-server is an addon maintained by Kubernetes. For any concerns contact minikube on GitHub.\n",
      "You can view the list of minikube maintainers at: https://github.com/kubernetes/minikube/blob/master/OWNERS\n",
      "    ▪ Using image registry.k8s.io/metrics-server/metrics-server:v0.6.4\n",
      "🌟  The 'metrics-server' addon is enabled\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n",
      "|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n",
      "| ambassador                  | minikube | disabled     | 3rd party (Ambassador)         |\n",
      "| auto-pause                  | minikube | disabled     | minikube                       |\n",
      "| cloud-spanner               | minikube | disabled     | Google                         |\n",
      "| csi-hostpath-driver         | minikube | disabled     | Kubernetes                     |\n",
      "| dashboard                   | minikube | disabled     | Kubernetes                     |\n",
      "| default-storageclass        | minikube | disabled     | Kubernetes                     |\n",
      "| efk                         | minikube | disabled     | 3rd party (Elastic)            |\n",
      "| freshpod                    | minikube | disabled     | Google                         |\n",
      "| gcp-auth                    | minikube | disabled     | Google                         |\n",
      "| gvisor                      | minikube | disabled     | minikube                       |\n",
      "| headlamp                    | minikube | disabled     | 3rd party (kinvolk.io)         |\n",
      "| helm-tiller                 | minikube | disabled     | 3rd party (Helm)               |\n",
      "| inaccel                     | minikube | disabled     | 3rd party (InAccel             |\n",
      "|                             |          |              | [info@inaccel.com])            |\n",
      "| ingress                     | minikube | disabled     | Kubernetes                     |\n",
      "| ingress-dns                 | minikube | disabled     | minikube                       |\n",
      "| inspektor-gadget            | minikube | disabled     | 3rd party                      |\n",
      "|                             |          |              | (inspektor-gadget.io)          |\n",
      "| istio                       | minikube | disabled     | 3rd party (Istio)              |\n",
      "| istio-provisioner           | minikube | disabled     | 3rd party (Istio)              |\n",
      "| kong                        | minikube | disabled     | 3rd party (Kong HQ)            |\n",
      "| kubeflow                    | minikube | disabled     | 3rd party                      |\n",
      "| kubevirt                    | minikube | disabled     | 3rd party (KubeVirt)           |\n",
      "| logviewer                   | minikube | disabled     | 3rd party (unknown)            |\n",
      "| metallb                     | minikube | disabled     | 3rd party (MetalLB)            |\n",
      "| metrics-server              | minikube | enabled ✅   | Kubernetes                     |\n",
      "| nvidia-device-plugin        | minikube | disabled     | 3rd party (NVIDIA)             |\n",
      "| nvidia-driver-installer     | minikube | disabled     | 3rd party (Nvidia)             |\n",
      "| nvidia-gpu-device-plugin    | minikube | disabled     | 3rd party (Nvidia)             |\n",
      "| olm                         | minikube | disabled     | 3rd party (Operator Framework) |\n",
      "| pod-security-policy         | minikube | disabled     | 3rd party (unknown)            |\n",
      "| portainer                   | minikube | disabled     | 3rd party (Portainer.io)       |\n",
      "| registry                    | minikube | disabled     | minikube                       |\n",
      "| registry-aliases            | minikube | disabled     | 3rd party (unknown)            |\n",
      "| registry-creds              | minikube | disabled     | 3rd party (UPMC Enterprises)   |\n",
      "| storage-provisioner         | minikube | disabled     | minikube                       |\n",
      "| storage-provisioner-gluster | minikube | disabled     | 3rd party (Gluster)            |\n",
      "| storage-provisioner-rancher | minikube | disabled     | 3rd party (Rancher)            |\n",
      "| volumesnapshots             | minikube | disabled     | Kubernetes                     |\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n"
     ]
    }
   ],
   "source": [
    "!minikube addons enable metrics-server\n",
    "!minikube addons list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Metrics Server (if not using Minikube)\n",
    "\n",
    "- To check if the Metrics Server is installed in your cluster, look for a pod called `metrics-server` in the `kube-system` namespace\n",
    "  -  `kubectl get po -n kube-system`\n",
    "- To install the Metrics Server\n",
    "  - Download the YAML file `components.yaml` from `https://github.com/kubernetes-sigs/metrics-server/releases`\n",
    "  - Edit the `components.yaml` file and add the parameter `- --kubelet-insecure-tls` to the `Deployment` section.\n",
    "    - This enables the Metrics Server to run if TLS is not configured.\n",
    "  - Install the Metrics Server with `kubectl apply -f components.yaml`.\n",
    "\n",
    "```bash\n",
    "# components.yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  labels:\n",
    "    k8s-app: metrics-server\n",
    "  name: metrics-server\n",
    "  namespace: kube-system\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      k8s-app: metrics-server\n",
    "  strategy:\n",
    "    rollingUpdate:\n",
    "      maxUnavailable: 0\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        k8s-app: metrics-server\n",
    "    spec:\n",
    "      containers:\n",
    "      - args:\n",
    "        - --cert-dir=/tmp\n",
    "        - --secure-port=443\n",
    "        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\n",
    "        - --kubelet-use-node-status-port\n",
    "        - --kubelet-insecure-tls # <-------------------------------------------- Add this line\n",
    "        - --metric-resolution=15s\n",
    "        image: k8s.gcr.io/metrics-server/metrics-server:v0.5.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f manifests/components.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Deployment called `nginx-deployment`\n",
    "\n",
    "- The Deployment definitions is in the YAML file `manifests/nginx-deployment.yaml`\n",
    "  - The Deployment's name is `nginx-deployment`.\n",
    "  - It has `replicas` set to `1`.\n",
    "  - It's Pod template uses Docker image `nginx:alpine`.\n",
    "  - The name of it's container is `nginx`.\n",
    "  - It's container listens on `containerPort` `80`.\n",
    "  - It has it's `resources` defined as below:\n",
    "\n",
    "    ```bash\n",
    "    resources:           # The container's resources are defined below\n",
    "      \n",
    "      requests:          # The minimum resourcs the container is requesting is:\n",
    "        cpu: 200m        # A minimum of 200 millicores (CPU)\n",
    "        memory: 126Mi    # A minimum of 126 mebibytes (RAM)\n",
    "      \n",
    "      limits:            # The maximum resourcs the container is requesting to burst to if needed is:\n",
    "        cpu: 500m        # A minimum of 500 millicores (CPU)\n",
    "        memory: 256Mi    # A minimum of 256 mebibytes (RAM)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/nginx-deployment created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f manifests/nginx-deployment.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Service called `nginx-service`\n",
    "\n",
    "- The Service definitions is in the YAML file `manifests/nginx-service.yaml`\n",
    "  - The Service's name is `nginx-service`.\n",
    "  - It listens on `port` `80`.\n",
    "  - It redirects traffic to `targetPort` `80`.\n",
    "  - It's selector selects the Pod's created by the Deployment's Pod template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/nginx-service created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f manifests/nginx-service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Deployments, ReplicaSets, Pods and Services\n",
    "\n",
    "- We see the Deployment with one associated ReplicaSet and Pod, and the Service have been created.\n",
    "  - Notice that there is only 1 pod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                    READY   STATUS    RESTARTS   AGE   IP            NODE           NOMINATED NODE   READINESS GATES\n",
      "pod/nginx-deployment-86c598b675-2smfc   1/1     Running   0          16s   10.244.1.12   minikube-m02   <none>           <none>\n",
      "\n",
      "NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE    SELECTOR\n",
      "service/kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP   107m   <none>\n",
      "service/nginx-service   ClusterIP   10.109.215.212   <none>        80/TCP    12s    app=nginx\n",
      "\n",
      "NAME                               READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR\n",
      "deployment.apps/nginx-deployment   1/1     1            1           16s   nginx        nginx:alpine   app=nginx\n",
      "\n",
      "NAME                                          DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES         SELECTOR\n",
      "replicaset.apps/nginx-deployment-86c598b675   1         1         1       16s   nginx        nginx:alpine   app=nginx,pod-template-hash=86c598b675\n"
     ]
    }
   ],
   "source": [
    "#!kubectl get deployments -o wide\n",
    "#!kubectl get replicasets -o wide\n",
    "#!kubectl get pods -o wide\n",
    "#!kubectl get services -o wide\n",
    "!kubectl get all -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HPA with autoscaling limits for Deployment `nginx-deployment`\n",
    "\n",
    "- The Horizontal Pod Autoscaler (HPA) is defined in the file `manifests/hpa-cpu.yaml`.\n",
    "  - The equivalent imperative command to the declarative YAML file is:\n",
    "\n",
    "    ```bash\n",
    "    kubectl autoscale deployment nginx-deployment --name hpa-cpu --cpu-percent=5 --min=2 --max=4\n",
    "    ```\n",
    "  - The HPA's name is `hpa-cpu`.\n",
    "  - It sets `minReplicas` to `2`.\n",
    "  - It sets `maxReplicas` to `10`.\n",
    "  - It's `scaleTargetRef` targets the Deployment `nginx-deployment`.\n",
    "  - It monitors `metrics` for the `cpu` `resource` `type`.\n",
    "    -  It's `target` is of `type` `Utilization` with `averageUtilization` set to `5`.\n",
    "  - This means the HPA will autoscale `nginx-deployment` Deployment's Pod `replicas` based on:\n",
    "    - The average CPU utilization across all Pod `replicas` reaching the threshold value `5%`.\n",
    "      - If average CPU utilization goes above `5%`, the HPA will add more Pods.\n",
    "      - If average CPU utilization goes below `5%`, the HPA will remove Pods.\n",
    "\n",
    "```bash\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: hpa-cpu\n",
    "spec:\n",
    "  \n",
    "  minReplicas: 2                 # When autoscaling in, don't go below 2 Pods\n",
    "  maxReplicas: 10                # When autoscaling out, don't go over 10 Pods\n",
    "  \n",
    "  scaleTargetRef:                # The settings below determine what resouce to monitor and autoscale\n",
    "    apiVersion: apps/v1            # This matches the \"apiVersion\" set in the Deployment's YAML definition\n",
    "    kind: Deployment               # This matches the \"kind\" set in the Deployment's YAML definition\n",
    "    name: nginx-deployment         # This matches the \"name\" set in the Deployment's YAML definition\n",
    "  \n",
    "  metrics:                       # The settings below determine what metrics to monitor (it's a list, only one item in this case)\n",
    "  - type: Resource                 # The type of metric to monitor is a \"Resource\"\n",
    "    resource:                      # The properties for the \"resource\" are specified below\n",
    "      name: cpu                      # The resource monitored is \"cpu\"\n",
    "      target:                        # The target for the monitored resource is specified below\n",
    "        type: Utilization              # The target type is \"Utilization\"\n",
    "        averageUtilization: 2          # The threshold for the target is an \"averageUtilization\" of \"2\" percent (5%)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontalpodautoscaler.autoscaling/hpa-cpu created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f manifests/hpa-cpu.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Horizontal Pod Autoscalers (HPAs)\n",
    "\n",
    "- We see that:\n",
    "  - The `hpa-cpu` HPA references the `nginx-deployment` Deployment.\n",
    "  - It's `TARGETS` show the current value (`0%`) and the threshold value (`2%`) of the target metric.\n",
    "  - It's `MINPODS` is set to `2`.\n",
    "  - It's `MAXPODS` is set to `10`.\n",
    "  - The current number of Pod `REPLICAS` it has autoscaled to is `2`.\n",
    "\n",
    "You can also run the command `kubectl get hpa -o wide --watch` in a separate terminal to see the HPA's alues changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   0%/2%     2         10        2          79s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Pod called `busybox-pod`\n",
    "\n",
    "- The Pod's definition is in the YAML file `manifests/busybox-pod.yaml`.\n",
    "  - It name is `busybox-pod`.\n",
    "  - We will remote into this Pod, and use it to apply a load on the `nginx` containers.\n",
    "    - This will increase the average CPU utilization of the Pod replicas, causing the HPA to autoscale the Pod replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/busybox-pod created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f manifests/busybox-pod.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the BusyBox Pod's container and increase load on Nginx\n",
    "\n",
    "- Run these commands in a terminal (won't work from a notebook cell).\n",
    "\n",
    "```bash\n",
    "\n",
    "# Open an interactive session to the BusyBox Pod's container\n",
    "kubectl exec busybox-pod -it -- /bin/sh\n",
    "\n",
    "# --- Output ---\n",
    "# / #\n",
    "# / #\n",
    "# --------------\n",
    "\n",
    "# Increase load on the Nginx web server Pods\n",
    "while true; do wget --server-response http://nginx-service 2>&1 | awk '/^  HTTP/{printf $3 \" \"}'; done\n",
    "\n",
    "# --- Output ---\n",
    "# \n",
    "# --------------\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Horizontal Pod Autoscalers (HPAs)\n",
    "\n",
    "- We see that:\n",
    "  - The current target value under `TARGETS`\n",
    "    - First increases to `4%` above the threshold target value `2%`.\n",
    "    - Then decreases to `2%` as the HPA scales out more Pods.\n",
    "    - The threshold target values is still `2%`.\n",
    "  - The HPA has autoscaled the number of Pod `REPLICAS` from `2` to `4`.\n",
    "    - The `MINPODS` and `MAXPODS` is still `2` and `10` respectively.\n",
    "\n",
    "You can also run the command `kubectl get hpa -o wide --watch` in a separate terminal to see the HPA's alues changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   4%/2%     2         10        2          3m20s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa -o wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   4%/2%     2         10        4          3m32s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa -o wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   3%/2%     2         10        4          4m17s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa -o wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   2%/2%     2         10        4          5m16s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop the endless loop in the terminal running BusyBox\n",
    "\n",
    "```bash\n",
    "# Press Ctrl + C in the terminal with the interactive shell to BusyBox to terminate the while loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Horizontal Pod Autoscalers (HPAs)\n",
    "\n",
    "- We see that:\n",
    "- The current target value under `TARGETS`\n",
    "    - First decreases to `1%` under the threshold target value `2%`.\n",
    "    - Continues to decreases to `0%` as the load on the Nginx web server replcas reduces.\n",
    "    - The threshold target values is still `2%`.\n",
    "  - The HPA has autoscaled the number of Pod `REPLICAS` from `4` to `2`.\n",
    "    - The `MINPODS` and `MAXPODS` is still `2` and `10` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   2%/2%     2         10        4          5m38s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   1%/2%     2         10        4          6m17s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   1%/2%     2         10        2          6m32s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "hpa-cpu   Deployment/nginx-deployment   0%/2%     2         10        2          7m17s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Horizontal Pod Autoscaler (HPA)\n",
    "\n",
    "**Note**\n",
    "\n",
    "- When you delete an HPA, the current number of replicas for the Deployment the HPA is autoscaling will remain.\n",
    "  - The number of replicas won't revert back to the `replicas` setting in the Deployment's YAML file.\n",
    "- The desired amount of replicas has to be set manually after deleting the HPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontalpodautoscaler.autoscaling \"hpa-cpu\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete hpa hpa-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the BusyBox Pod, Service and Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1mWarning:\u001b[0m Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n",
      "pod \"busybox-pod\" force deleted\n",
      "service \"nginx-service\" deleted\n",
      "deployment.apps \"nginx-deployment\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f manifests/busybox-pod.yaml --grace-period=0 --force\n",
    "!kubectl delete -f manifests/nginx-service.yaml\n",
    "!kubectl delete -f manifests/nginx-deployment.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with other HPA YAML files\n",
    "\n",
    "- There are an additional two YAML files for the HPA that you can experiment with:\n",
    "  - `manifests/hpa-memory.yaml` that sets a memory (RAM) target instead of a CPU target.\n",
    "  - `manifests/hpa-cpu-memory.yaml` that includes both a CPU and a memory target.\n",
    "- Repeat this notebook, but use these YAML files instead of `manifests/hpa-cpu.yaml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable the `metrics-server` Minikube addon (if using Minikube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌑  \"The 'metrics-server' addon is disabled\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n",
      "|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n",
      "| ambassador                  | minikube | disabled     | 3rd party (Ambassador)         |\n",
      "| auto-pause                  | minikube | disabled     | minikube                       |\n",
      "| cloud-spanner               | minikube | disabled     | Google                         |\n",
      "| csi-hostpath-driver         | minikube | disabled     | Kubernetes                     |\n",
      "| dashboard                   | minikube | disabled     | Kubernetes                     |\n",
      "| default-storageclass        | minikube | disabled     | Kubernetes                     |\n",
      "| efk                         | minikube | disabled     | 3rd party (Elastic)            |\n",
      "| freshpod                    | minikube | disabled     | Google                         |\n",
      "| gcp-auth                    | minikube | disabled     | Google                         |\n",
      "| gvisor                      | minikube | disabled     | minikube                       |\n",
      "| headlamp                    | minikube | disabled     | 3rd party (kinvolk.io)         |\n",
      "| helm-tiller                 | minikube | disabled     | 3rd party (Helm)               |\n",
      "| inaccel                     | minikube | disabled     | 3rd party (InAccel             |\n",
      "|                             |          |              | [info@inaccel.com])            |\n",
      "| ingress                     | minikube | disabled     | Kubernetes                     |\n",
      "| ingress-dns                 | minikube | disabled     | minikube                       |\n",
      "| inspektor-gadget            | minikube | disabled     | 3rd party                      |\n",
      "|                             |          |              | (inspektor-gadget.io)          |\n",
      "| istio                       | minikube | disabled     | 3rd party (Istio)              |\n",
      "| istio-provisioner           | minikube | disabled     | 3rd party (Istio)              |\n",
      "| kong                        | minikube | disabled     | 3rd party (Kong HQ)            |\n",
      "| kubeflow                    | minikube | disabled     | 3rd party                      |\n",
      "| kubevirt                    | minikube | disabled     | 3rd party (KubeVirt)           |\n",
      "| logviewer                   | minikube | disabled     | 3rd party (unknown)            |\n",
      "| metallb                     | minikube | disabled     | 3rd party (MetalLB)            |\n",
      "| metrics-server              | minikube | disabled     | Kubernetes                     |\n",
      "| nvidia-device-plugin        | minikube | disabled     | 3rd party (NVIDIA)             |\n",
      "| nvidia-driver-installer     | minikube | disabled     | 3rd party (Nvidia)             |\n",
      "| nvidia-gpu-device-plugin    | minikube | disabled     | 3rd party (Nvidia)             |\n",
      "| olm                         | minikube | disabled     | 3rd party (Operator Framework) |\n",
      "| pod-security-policy         | minikube | disabled     | 3rd party (unknown)            |\n",
      "| portainer                   | minikube | disabled     | 3rd party (Portainer.io)       |\n",
      "| registry                    | minikube | disabled     | minikube                       |\n",
      "| registry-aliases            | minikube | disabled     | 3rd party (unknown)            |\n",
      "| registry-creds              | minikube | disabled     | 3rd party (UPMC Enterprises)   |\n",
      "| storage-provisioner         | minikube | disabled     | minikube                       |\n",
      "| storage-provisioner-gluster | minikube | disabled     | 3rd party (Gluster)            |\n",
      "| storage-provisioner-rancher | minikube | disabled     | 3rd party (Rancher)            |\n",
      "| volumesnapshots             | minikube | disabled     | Kubernetes                     |\n",
      "|-----------------------------|----------|--------------|--------------------------------|\n"
     ]
    }
   ],
   "source": [
    "!minikube addons disable metrics-server\n",
    "!minikube addons list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uninstall the Metrics Server (if not using Minikube)\n",
    "\n",
    "- To uninstall the Metrics Server run the command: `kubectl delete -f components.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f manifests/components.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Cluster\n",
    "\n",
    "- Delete your specific cluster\n",
    "  - This example uses Minikube, so the command is:\n",
    "\n",
    "    ```bash\n",
    "    minikube stop\n",
    "    minikube delete\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
